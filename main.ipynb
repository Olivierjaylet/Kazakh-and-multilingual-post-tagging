{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 317,
     "status": "ok",
     "timestamp": 1729149620190,
     "user": {
      "displayName": "Olivier Jaylet",
      "userId": "17139053766533794240"
     },
     "user_tz": -300
    },
    "id": "eTiJKDRPOrsY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import  train_test_split\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "# Benchmark Model\n",
    "import nltk\n",
    "from nltk.tag import DefaultTagger, UnigramTagger, BigramTagger, TrigramTagger\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus.reader import TaggedCorpusReader\n",
    "from nltk.metrics import precision, recall, f_measure\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Home-made functions\n",
    "#from functions import *\n",
    "from fn_feature import *\n",
    "from fn_nltk import *\n",
    "from fn_results import *\n",
    "from nltk_func import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import & clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_kz = 'data/kdt-NLANU-0.01.connlu.txt'\n",
    "path_en = 'data/en_ewt-ud-dev.conllu'\n",
    "\n",
    "path_data = [\n",
    "    path_kz, \n",
    "    path_en\n",
    "    ]\n",
    "\n",
    "languages = [\n",
    "    'kazakh',\n",
    "    'english'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(train_data, test_data):\n",
    "\n",
    "    # Train taggers with backoff\n",
    "    unigram_tagger = UnigramTagger(train_data)\n",
    "    bigram_tagger = BigramTagger(train_data, backoff=unigram_tagger)\n",
    "    trigram_tagger = TrigramTagger(train_data, backoff=bigram_tagger)\n",
    "\n",
    "    # Helper function to calculate metrics\n",
    "    def calculate_metrics(tagger, data):\n",
    "        y_true = [pos for sentence in data for _, pos in sentence]\n",
    "        y_pred = [tag for sentence in data for _, tag in tagger.tag([word for word, _ in sentence])]\n",
    "        return {\n",
    "            'Precision': precision(set(y_true), set(y_pred)),\n",
    "            'Recall': recall(set(y_true), set(y_pred)),\n",
    "            'F1-Score': f_measure(set(y_true), set(y_pred)),\n",
    "        }\n",
    "\n",
    "    # Calculate metrics for train and test data for each tagger\n",
    "    metrics = {\n",
    "    'Metric': [\n",
    "        'Train Precision', 'Test Precision', 'Train Recall', 'Test Recall', 'Train F1-Score', 'Test F1-Score'\n",
    "    ],\n",
    "    'Unigram': [\n",
    "        calculate_metrics(unigram_tagger, train_data)['Precision'],\n",
    "        calculate_metrics(unigram_tagger, test_data)['Precision'],\n",
    "        calculate_metrics(unigram_tagger, train_data)['Recall'],\n",
    "        calculate_metrics(unigram_tagger, test_data)['Recall'],\n",
    "        calculate_metrics(unigram_tagger, train_data)['F1-Score'],\n",
    "        calculate_metrics(unigram_tagger, test_data)['F1-Score']\n",
    "    ],\n",
    "    'Bigram': [\n",
    "        calculate_metrics(bigram_tagger, train_data)['Precision'],\n",
    "        calculate_metrics(bigram_tagger, test_data)['Precision'],\n",
    "        calculate_metrics(bigram_tagger, train_data)['Recall'],\n",
    "        calculate_metrics(bigram_tagger, test_data)['Recall'],\n",
    "        calculate_metrics(bigram_tagger, train_data)['F1-Score'],\n",
    "        calculate_metrics(bigram_tagger, test_data)['F1-Score']\n",
    "    ],\n",
    "    'Trigram': [\n",
    "        calculate_metrics(trigram_tagger, train_data)['Precision'],\n",
    "        calculate_metrics(trigram_tagger, test_data)['Precision'],\n",
    "        calculate_metrics(trigram_tagger, train_data)['Recall'],\n",
    "        calculate_metrics(trigram_tagger, test_data)['Recall'],\n",
    "        calculate_metrics(trigram_tagger, train_data)['F1-Score'],\n",
    "        calculate_metrics(trigram_tagger, test_data)['F1-Score']\n",
    "    ]\n",
    "    }\n",
    "\n",
    "    # Create a DataFrame to store the results\n",
    "    metrics_df = pd.DataFrame(metrics)\n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________ KAZAKH CORPUS ____________________________\n",
      "Unigram Tagger Accuracy: 0.9416345259822997\n",
      "Bigram Tagger Accuracy: 0.809618099796825\n",
      "Tigram Tagger Accuracy: 0.7593193636144495\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Unigram</th>\n",
       "      <th>Bigram</th>\n",
       "      <th>Trigram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train Precision</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test Precision</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train Recall</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Test Recall</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train F1-Score</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Test F1-Score</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.971429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Metric   Unigram    Bigram   Trigram\n",
       "0  Train Precision  1.000000  1.000000  1.000000\n",
       "1   Test Precision  0.941176  0.944444  0.944444\n",
       "2     Train Recall  0.941176  1.000000  1.000000\n",
       "3      Test Recall  0.941176  1.000000  1.000000\n",
       "4   Train F1-Score  0.969697  1.000000  1.000000\n",
       "5    Test F1-Score  0.941176  0.971429  0.971429"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Multi-language POS Tagger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test Accuracy</td>\n",
       "      <td>0.951953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test F1 Score</td>\n",
       "      <td>0.951309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Test Recall</td>\n",
       "      <td>0.951953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train Accuracy</td>\n",
       "      <td>0.957085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train F1 Score</td>\n",
       "      <td>0.956441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Train Recall</td>\n",
       "      <td>0.957085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Metric  Multi-language POS Tagger\n",
       "0   Test Accuracy                   0.951953\n",
       "1   Test F1 Score                   0.951309\n",
       "2     Test Recall                   0.951953\n",
       "3  Train Accuracy                   0.957085\n",
       "4  Train F1 Score                   0.956441\n",
       "5    Train Recall                   0.957085"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [07:48, 468.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________ ENGLISH CORPUS ____________________________\n",
      "Unigram Tagger Accuracy: 0.7336946003483646\n",
      "Bigram Tagger Accuracy: 0.14631314108767177\n",
      "Tigram Tagger Accuracy: 0.10354170698664603\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Unigram</th>\n",
       "      <th>Bigram</th>\n",
       "      <th>Trigram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train Precision</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test Precision</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train Recall</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Test Recall</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train F1-Score</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Test F1-Score</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.972973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Metric   Unigram    Bigram   Trigram\n",
       "0  Train Precision  1.000000  1.000000  1.000000\n",
       "1   Test Precision  0.947368  0.947368  0.947368\n",
       "2     Train Recall  1.000000  1.000000  1.000000\n",
       "3      Test Recall  1.000000  1.000000  1.000000\n",
       "4   Train F1-Score  1.000000  1.000000  1.000000\n",
       "5    Test F1-Score  0.972973  0.972973  0.972973"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Multi-language POS Tagger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test Accuracy</td>\n",
       "      <td>0.825431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test F1 Score</td>\n",
       "      <td>0.826527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Test Recall</td>\n",
       "      <td>0.825431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train Accuracy</td>\n",
       "      <td>0.936741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train F1 Score</td>\n",
       "      <td>0.936978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Train Recall</td>\n",
       "      <td>0.936741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Metric  Multi-language POS Tagger\n",
       "0   Test Accuracy                   0.825431\n",
       "1   Test F1 Score                   0.826527\n",
       "2     Test Recall                   0.825431\n",
       "3  Train Accuracy                   0.936741\n",
       "4  Train F1 Score                   0.936978\n",
       "5    Train Recall                   0.936741"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [08:13, 246.75s/it]\n"
     ]
    }
   ],
   "source": [
    "columns = [\"ID\", \"WORD\", \"LEMMA\", \"POS\", \"XPOS\", \"MORPH\", \"HEAD\", \"DEPREL\", \"DEPS\", \"MISC\"]\n",
    "\n",
    "for path, lang in tqdm(zip(path_data, languages)) :\n",
    "\n",
    "    print(\"____________________________\" , lang.upper(), \"CORPUS ____________________________\")\n",
    "\n",
    "    kazakh_sentences = parse_conllu(path)\n",
    "\n",
    "\n",
    "    cutoff = int(.75 * len(kazakh_sentences))\n",
    "    training_sentences = kazakh_sentences[:cutoff]\n",
    "    test_sentences = kazakh_sentences[cutoff:]\n",
    "\n",
    "    X_train, y_train = transform_to_dataset(training_sentences)\n",
    "    X_test, y_test = transform_to_dataset(test_sentences)\n",
    "\n",
    "    ################################################\n",
    "    ################## NLTK MODEL ##################\n",
    "    ################################################\n",
    "    \n",
    "    train_data = []\n",
    "    sent = []\n",
    "    for w, t in zip(X_train, y_train):\n",
    "        if not w['is_last']:\n",
    "            sent.append((w['word'], t))\n",
    "        else:\n",
    "            sent.append((w['word'], t))\n",
    "            train_data.append(sent)\n",
    "            sent = []\n",
    "\n",
    "    test_data = []\n",
    "    sent = []\n",
    "    for w, t in zip(X_test, y_test):\n",
    "        if not w['is_last']:\n",
    "            sent.append((w['word'], t))\n",
    "        else:\n",
    "            sent.append((w['word'], t))\n",
    "            test_data.append(sent)\n",
    "            sent = []\n",
    "\n",
    "\n",
    "    y_test = [pos for sentence in test_data for _, pos in sentence]\n",
    "\n",
    "    unigram_tagger = UnigramTagger(train_data)\n",
    "    print(\"Unigram Tagger Accuracy:\", unigram_tagger.evaluate(test_data)) \n",
    "\n",
    "    bigram_tagger = BigramTagger(train_data)\n",
    "    print(\"Bigram Tagger Accuracy:\", bigram_tagger.evaluate(test_data)) \n",
    "\n",
    "    trigram_tagger = TrigramTagger(train_data)\n",
    "    print(\"Tigram Tagger Accuracy:\", trigram_tagger.evaluate(test_data)) \n",
    "\n",
    "    metrics_nltk = compute_metrics(train_data, test_data)\n",
    "\n",
    "    display(metrics_nltk)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #####################################################\n",
    "    ################ multi lingual model ################\n",
    "    #####################################################\n",
    "    X_lex, Y_lex = get_values(kazakh_sentences)\n",
    "\n",
    "    X_test, y_test = extract_words_and_tags(test_data)\n",
    "    X_train, y_train = extract_words_and_tags(train_data)\n",
    "\n",
    "    #get max word length\n",
    "    max_word_len = max(max([len(w) for w in Y_lex]), max([len(w) for w in X_lex]))\n",
    "\n",
    "    #Char2vec model\n",
    "    vectorizer = TfidfVectorizer(lowercase=False, \n",
    "                                analyzer='char'\n",
    "                                )\n",
    "\n",
    "    X = vectorizer.fit_transform(X_lex)\n",
    "    dic = vectorizer.get_feature_names_out() # letter dictionary\n",
    "    num_letters = len(dic)\n",
    "    mx = X.T.dot(X) # letter cooccurence matrix\n",
    "    mx = mx.toarray()\n",
    "\n",
    "    #Vectorize X only\n",
    "    X_lex_vec_train = [alpha_vec2(w, mx, max_word_len, dic) for w in X_train]\n",
    "    X_lex_vec_test = [alpha_vec2(w, mx, max_word_len, dic) for w in X_test]\n",
    "\n",
    "    # Encode Y\n",
    "    list_tags = list_all_POS_tags(y = y_train)\n",
    "    encoder_tag = LabelEncoder().fit(list_tags)\n",
    "\n",
    "    Y_train = encoder_tag.transform(y_train)\n",
    "    Y_test = encoder_tag.transform(y_test)\n",
    "\n",
    "    # Build & train model\n",
    "    best_model = ExtraTreesClassifier(n_estimators=10,\n",
    "                                    n_jobs=-1,\n",
    "                                    criterion='entropy',\n",
    "                                    bootstrap=True\n",
    "                                    )\n",
    "\n",
    "    best_model.fit(X_lex_vec_train, Y_train)\n",
    "\n",
    "    # predict both train and test sets\n",
    "    predicts_test = best_model.predict(X_lex_vec_test)\n",
    "    predicts_train = best_model.predict(X_lex_vec_train)\n",
    "\n",
    "    \n",
    "    #####################################################################################################\n",
    "    ########################################## result analysis ##########################################\n",
    "    #####################################################################################################\n",
    "    test_acc, test_f1, test_recall, train_acc, train_f1, train_recall = calculate_results(Y_test, \n",
    "                                                                                            Y_train, \n",
    "                                                                                            predicts_test, \n",
    "                                                                                            predicts_train\n",
    "                                                                                            )\n",
    "    \n",
    "\n",
    "\n",
    "    data = {\n",
    "        \"Metric\": [\"Test Accuracy\", \"Test F1 Score\", \"Test Recall\", \n",
    "                \"Train Accuracy\", \"Train F1 Score\", \"Train Recall\"],\n",
    "        \"Multi-language POS Tagger\": [test_acc, test_f1, test_recall,\n",
    "                        train_acc, train_f1, train_recall]\n",
    "    }\n",
    "\n",
    "    # Create the DataFrame\n",
    "    df_results = pd.DataFrame(data)\n",
    "\n",
    "    # Display the DataFrame\n",
    "    display(df_results)\n",
    "\n",
    "    '''\n",
    "    fig = plot_confusion_matrix(Y_test, predicts_test, list_tags, 'Test set', lang)\n",
    "    save_graph_to_folder(fig, lang, 'confusion_matrix_test')\n",
    "    \n",
    "    fig = plot_confusion_matrix(Y_train, predicts_train, list_tags, 'Train set', lang)\n",
    "    save_graph_to_folder(fig, lang, 'confusion_matrix_train')\n",
    "\n",
    "    df_tag_acc = per_tag_accuracy(Y_test, \n",
    "                              predicts_test, \n",
    "                              list_tags, \n",
    "                              encoder_tag\n",
    "                              )\n",
    "\n",
    "    display(df_tag_acc) # display accuracy per Tag\n",
    "    \n",
    "    df_tag_dist = tag_prediction_nb(\n",
    "        Y_test, \n",
    "        predicts_test, \n",
    "        list_tags, \n",
    "        encoder_tag\n",
    "        )\n",
    "\n",
    "    display(df_tag_dist) # display the number of correct and incorect predictions for each tag\n",
    "\n",
    "\n",
    "    fig = plot_dist_predictions(df_tag_dist,\n",
    "                                lang)\n",
    "    save_graph_to_folder(fig, lang, 'dist_predictions')\n",
    "    \n",
    "    \n",
    "    mistake_freq_df = mistake_frequency_by_word_type(Y_test, \n",
    "                                                    predicts_test, \n",
    "                                                    list_tags, \n",
    "                                                    encoder_tag\n",
    "                                                    )\n",
    "\n",
    "    display(mistake_freq_df.head(n=10)) # Print 10 most frequent errors'''\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
