{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Olivier\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import  train_test_split\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.tag import DefaultTagger\n",
    "from nltk.tag import BigramTagger\n",
    "\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "\n",
    "from functions import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_kz = 'data/kdt-NLANU-0.01.connlu.txt'\n",
    "path_en = 'data/en_ewt-ud-dev.conllu'\n",
    "#path_tu = 'data/tr_kenet-ud-dev.conllu'\n",
    "\n",
    "path_data = [\n",
    "    path_kz, \n",
    "    path_en, \n",
    "#    path_tu\n",
    "    ]\n",
    "\n",
    "languages = [\n",
    "    'kazakh',\n",
    "    'english',\n",
    "#    'turkish'\n",
    "    ]\n",
    "\n",
    "dic_ = {}\n",
    "for l in languages : \n",
    "    dic_[l] = {\n",
    "            'test_acc' : '',\n",
    "            'test_f1' : '',\n",
    "            'train_acc' : '',\n",
    "            \"train_f1\" : '',\n",
    "            \"Y\" : '',\n",
    "            \"predicts\" : '', \n",
    "            \"list_tags\" : ''\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"ID\", \"WORD\", \"LEMMA\", \"POS\", \"XPOS\", \"MORPH\", \"HEAD\", \"DEPREL\", \"DEPS\", \"MISC\"]\n",
    "\n",
    "for path, lang in tqdm(zip(path_data, languages)) :\n",
    "\n",
    "    print(\"____________________________\" , lang.upper(), \"CORPUS ____________________________\")\n",
    "\n",
    "    # Read the file and convert it to a DataFrame\n",
    "    df = pd.read_csv(path,\n",
    "                    sep='\\t',\n",
    "                    names=columns,\n",
    "                    skip_blank_lines=True\n",
    "                    )\n",
    "\n",
    "    # run the hand-made function to clean data\n",
    "    X_lex, Y_lex = clean_data(df)\n",
    "    \n",
    "    # Split into train & test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_lex, \n",
    "                                                        Y_lex, \n",
    "                                                        test_size=0.1, \n",
    "                                                        random_state=42\n",
    "                                                        )\n",
    "\n",
    "    #get max word length\n",
    "    max_word_len = max(max([len(w) for w in Y_lex]), max([len(w) for w in X_lex]))\n",
    "\n",
    "    #Char2vec model\n",
    "    vectorizer = TfidfVectorizer(lowercase=False, \n",
    "                                analyzer='char'\n",
    "                                )\n",
    "\n",
    "    X = vectorizer.fit_transform(X_lex)\n",
    "    dic = vectorizer.get_feature_names_out() # letter dictionary\n",
    "    num_letters = len(dic)\n",
    "    mx = X.T.dot(X) # letter cooccurence matrix\n",
    "    mx = mx.toarray()\n",
    "\n",
    "    #Vectorize X only\n",
    "    X_lex_vec_train = [alpha_vec2(w, mx, max_word_len, dic) for w in X_train]\n",
    "    X_lex_vec_test = [alpha_vec2(w, mx, max_word_len, dic) for w in X_test]\n",
    "\n",
    "    # Encode Y\n",
    "    list_tags = list_all_POS_tags(y = y_train)\n",
    "    encoder_tag = LabelEncoder().fit(list_tags)\n",
    "\n",
    "    Y_train = encoder_tag.transform(y_train)\n",
    "    Y_test = encoder_tag.transform(y_test)\n",
    "\n",
    "    # Build & train model\n",
    "    best_model = ExtraTreesClassifier(n_estimators=10,\n",
    "                                    n_jobs=-1,\n",
    "                                    criterion='entropy',\n",
    "                                    bootstrap=True\n",
    "                                    )\n",
    "\n",
    "    best_model.fit(X_lex_vec_train, Y_train)\n",
    "\n",
    "    # predict both train and test sets\n",
    "    predicts_test = best_model.predict(X_lex_vec_test)\n",
    "    predicts_train = best_model.predict(X_lex_vec_train)\n",
    "\n",
    "    test_acc, test_f1, train_acc, train_f1 = calculate_results(Y_test, \n",
    "                      Y_train, \n",
    "                      predicts_test, \n",
    "                      predicts_train\n",
    "                      )\n",
    "    print(\"Test Accuracy:\", round(test_acc, 3))\n",
    "    print(\"Test F1 Score:\", round(test_f1, 3))\n",
    "    print(\"Train Accuracy:\", round(train_acc, 3))\n",
    "    print(\"Train F1 Score:\", round(train_f1, 3))\n",
    "\n",
    "    fig = plot_confusion_matrix(Y_test, predicts_test, list_tags, 'Test set', lang)\n",
    "    save_graph_to_folder(fig, lang, 'confusion_matrix_test')\n",
    "    \n",
    "    fig = plot_confusion_matrix(Y_train, predicts_train, list_tags, 'Train set', lang)\n",
    "    save_graph_to_folder(fig, lang, 'confusion_matrix_train')\n",
    "\n",
    "    df_tag_acc = per_tag_accuracy(Y_test, \n",
    "                              predicts_test, \n",
    "                              list_tags, \n",
    "                              encoder_tag\n",
    "                              )\n",
    "\n",
    "    display(df_tag_acc) # display accuracy per Tag\n",
    "    \n",
    "    df_tag_dist = tag_prediction_nb(\n",
    "        Y_test, \n",
    "        predicts_test, \n",
    "        list_tags, \n",
    "        encoder_tag\n",
    "        )\n",
    "\n",
    "    display(df_tag_dist) # display the number of correct and incorect predictions for each tag\n",
    "\n",
    "\n",
    "    fig = plot_dist_predictions(df_tag_dist,\n",
    "                                lang)\n",
    "    save_graph_to_folder(fig, lang, 'dist_predictions')\n",
    "    \n",
    "    \n",
    "    mistake_freq_df = mistake_frequency_by_word_type(Y_test, \n",
    "                                                    predicts_test, \n",
    "                                                    list_tags, \n",
    "                                                    encoder_tag\n",
    "                                                    )\n",
    "\n",
    "    display(mistake_freq_df.head(n=10)) # Print 10 most frequent errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "columns = [\"ID\", \"WORD\", \"LEMMA\", \"POS\", \"XPOS\", \"MORPH\", \"HEAD\", \"DEPREL\", \"DEPS\", \"MISC\"]\n",
    "\n",
    "\n",
    "df = pd.read_csv(path_kz,\n",
    "                sep='\\t',\n",
    "                names=columns,\n",
    "                skip_blank_lines=True\n",
    "                )\n",
    "\n",
    "# run the hand-made function to clean data\n",
    "X_lex, Y_lex = clean_data(df)\n",
    "\n",
    "\n",
    "# Split into train & test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_lex, \n",
    "                                                    Y_lex, \n",
    "                                                    test_size=0.1, \n",
    "                                                    random_state=42\n",
    "                                                    )\n",
    "\n",
    "#get max word length\n",
    "max_word_len = max(max([len(w) for w in Y_lex]), max([len(w) for w in X_lex]))\n",
    "\n",
    "#Char2vec model\n",
    "vectorizer = TfidfVectorizer(lowercase=False, \n",
    "                            analyzer='char'\n",
    "                            )\n",
    "\n",
    "\n",
    "X = vectorizer.fit_transform(X_lex)\n",
    "dic = vectorizer.get_feature_names_out() # letter dictionary\n",
    "num_letters = len(dic)\n",
    "mx = X.T.dot(X) # letter cooccurence matrix\n",
    "mx = mx.toarray()\n",
    "\n",
    "#Vectorize X only\n",
    "X_lex_vec_train = [alpha_vec2(w, mx, max_word_len, dic) for w in X_train]\n",
    "X_lex_vec_test = [alpha_vec2(w, mx, max_word_len, dic) for w in X_test]\n",
    "\n",
    "# Encode Y\n",
    "list_tags = list_all_POS_tags(y = y_train)\n",
    "encoder_tag = LabelEncoder().fit(list_tags)\n",
    "\n",
    "Y_train = encoder_tag.transform(y_train)\n",
    "Y_test = encoder_tag.transform(y_test)\n",
    "\n",
    "# Build & train model\n",
    "best_model = ExtraTreesClassifier(n_estimators=10,\n",
    "                                n_jobs=-1,\n",
    "                                criterion='entropy',\n",
    "                                bootstrap=True\n",
    "                                )\n",
    "\n",
    "best_model.fit(X_lex_vec_train, Y_train)\n",
    "\n",
    "# predict both train and test sets\n",
    "predicts_test = best_model.predict(X_lex_vec_test)\n",
    "predicts_train = best_model.predict(X_lex_vec_train)\n",
    "\n",
    "test_acc, test_f1, train_acc, train_f1 = calculate_results(Y_test, \n",
    "                    Y_train, \n",
    "                    predicts_test, \n",
    "                    predicts_train\n",
    "                    )\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"ID\", \"WORD\", \"LEMMA\", \"POS\", \"XPOS\", \"MORPH\", \"HEAD\", \"DEPREL\", \"DEPS\", \"MISC\"]\n",
    "\n",
    "df = pd.read_csv(path_en,\n",
    "                sep='\\t',\n",
    "                names=columns,\n",
    "                skip_blank_lines=True\n",
    "                )\n",
    "\n",
    "df_=df.head(n=300000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________ KAZAKH CORPUS ____________________________\n",
      "Size dataset :  (20000, 10)\n",
      "Test Accuracy: 0.854\n",
      "Test F1 Score: 0.851\n",
      "Test recall: 0.854\n",
      "Train Accuracy: 0.968\n",
      "Train F1 Score: 0.968\n",
      "Train recall: 0.968\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VERB</td>\n",
       "      <td>0.753799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>0.904918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PUNCT</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADV</td>\n",
       "      <td>0.559322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>0.662420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PROPN</td>\n",
       "      <td>0.865385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NUM</td>\n",
       "      <td>0.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PRON</td>\n",
       "      <td>0.896552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ADP</td>\n",
       "      <td>0.979798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AUX</td>\n",
       "      <td>0.528571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DET</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SCONJ</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Tag  Accuracy\n",
       "0    VERB  0.753799\n",
       "1    NOUN  0.904918\n",
       "2   PUNCT  1.000000\n",
       "3     ADV  0.559322\n",
       "4     ADJ  0.662420\n",
       "5   PROPN  0.865385\n",
       "6     NUM  0.820000\n",
       "7    PRON  0.896552\n",
       "8     ADP  0.979798\n",
       "9     AUX  0.528571\n",
       "10    DET  0.000000\n",
       "11   INTJ  1.000000\n",
       "12  SCONJ  1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>Correct Predictions</th>\n",
       "      <th>Incorrect Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VERB</td>\n",
       "      <td>248</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>552</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PUNCT</td>\n",
       "      <td>372</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADV</td>\n",
       "      <td>33</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>104</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PROPN</td>\n",
       "      <td>135</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NUM</td>\n",
       "      <td>41</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PRON</td>\n",
       "      <td>78</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ADP</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AUX</td>\n",
       "      <td>37</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DET</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SCONJ</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Tag  Correct Predictions  Incorrect Predictions\n",
       "0    VERB                  248                     81\n",
       "1    NOUN                  552                     58\n",
       "2   PUNCT                  372                      0\n",
       "3     ADV                   33                     26\n",
       "4     ADJ                  104                     53\n",
       "5   PROPN                  135                     21\n",
       "6     NUM                   41                      9\n",
       "7    PRON                   78                      9\n",
       "8     ADP                   97                      2\n",
       "9     AUX                   37                     33\n",
       "10    DET                    0                      1\n",
       "11   INTJ                    2                      0\n",
       "12  SCONJ                    8                      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From Tag</th>\n",
       "      <th>To Tag</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VERB</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>VERB</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VERB</td>\n",
       "      <td>AUX</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>AUX</td>\n",
       "      <td>VERB</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>PROPN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ADV</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>AUX</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   From Tag To Tag  Frequency\n",
       "0      VERB   NOUN         53\n",
       "21      ADJ   NOUN         32\n",
       "6      NOUN   VERB         24\n",
       "4      VERB    AUX         21\n",
       "40      AUX   VERB         20\n",
       "28    PROPN   NOUN         15\n",
       "8      NOUN    ADJ         13\n",
       "16      ADV   NOUN         11\n",
       "42      AUX    ADJ         11\n",
       "9      NOUN  PROPN          9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:09,  9.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________ ENGLISH CORPUS ____________________________\n",
      "Size dataset :  (20000, 10)\n",
      "Test Accuracy: 0.871\n",
      "Test F1 Score: 0.87\n",
      "Test recall: 0.871\n",
      "Train Accuracy: 0.949\n",
      "Train F1 Score: 0.948\n",
      "Train recall: 0.949\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DET</td>\n",
       "      <td>0.962733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SCONJ</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCONJ</td>\n",
       "      <td>0.980392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>0.871642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>0.717557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>VERB</td>\n",
       "      <td>0.786008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PRON</td>\n",
       "      <td>0.917197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADV</td>\n",
       "      <td>0.641304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PROPN</td>\n",
       "      <td>0.778443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AUX</td>\n",
       "      <td>0.926471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PUNCT</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ADP</td>\n",
       "      <td>0.979381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NUM</td>\n",
       "      <td>0.978261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Tag  Accuracy\n",
       "0     DET  0.962733\n",
       "1   SCONJ  0.652174\n",
       "2   CCONJ  0.980392\n",
       "3    NOUN  0.871642\n",
       "4     ADJ  0.717557\n",
       "5    VERB  0.786008\n",
       "6    PRON  0.917197\n",
       "7     ADV  0.641304\n",
       "8   PROPN  0.778443\n",
       "9     AUX  0.926471\n",
       "10  PUNCT  1.000000\n",
       "11    ADP  0.979381\n",
       "12   INTJ  0.500000\n",
       "13    NUM  0.978261"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>Correct Predictions</th>\n",
       "      <th>Incorrect Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DET</td>\n",
       "      <td>155</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SCONJ</td>\n",
       "      <td>30</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCONJ</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>292</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>94</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>VERB</td>\n",
       "      <td>191</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PRON</td>\n",
       "      <td>144</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADV</td>\n",
       "      <td>59</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PROPN</td>\n",
       "      <td>130</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AUX</td>\n",
       "      <td>126</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PUNCT</td>\n",
       "      <td>231</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ADP</td>\n",
       "      <td>190</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NUM</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Tag  Correct Predictions  Incorrect Predictions\n",
       "0     DET                  155                      6\n",
       "1   SCONJ                   30                     16\n",
       "2   CCONJ                   50                      1\n",
       "3    NOUN                  292                     43\n",
       "4     ADJ                   94                     37\n",
       "5    VERB                  191                     52\n",
       "6    PRON                  144                     13\n",
       "7     ADV                   59                     33\n",
       "8   PROPN                  130                     37\n",
       "9     AUX                  126                     10\n",
       "10  PUNCT                  231                      0\n",
       "11    ADP                  190                      4\n",
       "12   INTJ                    5                      5\n",
       "13    NUM                   45                      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From Tag</th>\n",
       "      <th>To Tag</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>VERB</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>PROPN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>VERB</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SCONJ</td>\n",
       "      <td>ADP</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ADV</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>VERB</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>VERB</td>\n",
       "      <td>AUX</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ADV</td>\n",
       "      <td>ADP</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   From Tag To Tag  Frequency\n",
       "16     VERB   NOUN         34\n",
       "34    PROPN   NOUN         25\n",
       "8      NOUN   VERB         21\n",
       "5     SCONJ    ADP         14\n",
       "12      ADJ   NOUN         14\n",
       "28      ADV    ADJ         12\n",
       "13      ADJ   VERB         11\n",
       "10     NOUN  PROPN         11\n",
       "19     VERB    AUX         10\n",
       "31      ADV    ADP         10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:24, 12.01s/it]\n"
     ]
    }
   ],
   "source": [
    "columns = [\"ID\", \"WORD\", \"LEMMA\", \"POS\", \"XPOS\", \"MORPH\", \"HEAD\", \"DEPREL\", \"DEPS\", \"MISC\"]\n",
    "\n",
    "for path, lang in tqdm(zip(path_data, languages)) :\n",
    "\n",
    "    print(\"____________________________\" , lang.upper(), \"CORPUS ____________________________\")\n",
    "\n",
    "    # Read the file and convert it to a DataFrame\n",
    "    df = pd.read_csv(path,\n",
    "                    sep='\\t',\n",
    "                    names=columns,\n",
    "                    skip_blank_lines=True\n",
    "                    )\n",
    "\n",
    "    # run the hand-made function to clean data\n",
    "    df = clean_data(df)\n",
    "\n",
    "    # data for home made tagger\n",
    "    X_lex, Y_lex = get_values(df)\n",
    "\n",
    "    # data for nltk tagger\n",
    "    \n",
    "\n",
    "    \n",
    "    # Split into train & test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_lex, \n",
    "                                                        Y_lex, \n",
    "                                                        test_size=0.1, \n",
    "                                                        random_state=42\n",
    "                                                        )\n",
    "\n",
    "    #get max word length\n",
    "    max_word_len = max(max([len(w) for w in Y_lex]), max([len(w) for w in X_lex]))\n",
    "\n",
    "    #Char2vec model\n",
    "    vectorizer = TfidfVectorizer(lowercase=False, \n",
    "                                analyzer='char'\n",
    "                                )\n",
    "\n",
    "    X = vectorizer.fit_transform(X_lex)\n",
    "    dic = vectorizer.get_feature_names_out() # letter dictionary\n",
    "    num_letters = len(dic)\n",
    "    mx = X.T.dot(X) # letter cooccurence matrix\n",
    "    mx = mx.toarray()\n",
    "\n",
    "    #Vectorize X only\n",
    "    X_lex_vec_train = [alpha_vec2(w, mx, max_word_len, dic) for w in X_train]\n",
    "    X_lex_vec_test = [alpha_vec2(w, mx, max_word_len, dic) for w in X_test]\n",
    "\n",
    "    # Encode Y\n",
    "    list_tags = list_all_POS_tags(y = y_train)\n",
    "    encoder_tag = LabelEncoder().fit(list_tags)\n",
    "\n",
    "    Y_train = encoder_tag.transform(y_train)\n",
    "    Y_test = encoder_tag.transform(y_test)\n",
    "\n",
    "    # Build & train model\n",
    "    best_model = ExtraTreesClassifier(n_estimators=10,\n",
    "                                    n_jobs=-1,\n",
    "                                    criterion='entropy',\n",
    "                                    bootstrap=True\n",
    "                                    )\n",
    "\n",
    "    best_model.fit(X_lex_vec_train, Y_train)\n",
    "\n",
    "    # predict both train and test sets\n",
    "    predicts_test = best_model.predict(X_lex_vec_test)\n",
    "    predicts_train = best_model.predict(X_lex_vec_train)\n",
    "\n",
    "    test_acc, test_f1, test_recall, train_acc, train_f1, train_recall = calculate_results(Y_test, \n",
    "                                                                                            Y_train, \n",
    "                                                                                            predicts_test, \n",
    "                                                                                            predicts_train\n",
    "                                                                                            )\n",
    "\n",
    "    print(\"Test Accuracy:\", round(test_acc, 3))\n",
    "    print(\"Test F1 Score:\", round(test_f1, 3))\n",
    "    print(\"Test recall:\", round(test_recall, 3))\n",
    "    print(\"Train Accuracy:\", round(train_acc, 3))\n",
    "    print(\"Train F1 Score:\", round(train_f1, 3))\n",
    "    print(\"Train recall:\", round(train_recall, 3))\n",
    "\n",
    "    fig = plot_confusion_matrix(Y_test, predicts_test, list_tags, 'Test set', lang)\n",
    "    save_graph_to_folder(fig, lang, 'confusion_matrix_test')\n",
    "    \n",
    "    fig = plot_confusion_matrix(Y_train, predicts_train, list_tags, 'Train set', lang)\n",
    "    save_graph_to_folder(fig, lang, 'confusion_matrix_train')\n",
    "\n",
    "    df_tag_acc = per_tag_accuracy(Y_test, \n",
    "                              predicts_test, \n",
    "                              list_tags, \n",
    "                              encoder_tag\n",
    "                              )\n",
    "\n",
    "    display(df_tag_acc) # display accuracy per Tag\n",
    "    \n",
    "    df_tag_dist = tag_prediction_nb(\n",
    "        Y_test, \n",
    "        predicts_test, \n",
    "        list_tags, \n",
    "        encoder_tag\n",
    "        )\n",
    "\n",
    "    display(df_tag_dist) # display the number of correct and incorect predictions for each tag\n",
    "\n",
    "\n",
    "    fig = plot_dist_predictions(df_tag_dist,\n",
    "                                lang)\n",
    "    save_graph_to_folder(fig, lang, 'dist_predictions')\n",
    "    \n",
    "    \n",
    "    mistake_freq_df = mistake_frequency_by_word_type(Y_test, \n",
    "                                                    predicts_test, \n",
    "                                                    list_tags, \n",
    "                                                    encoder_tag\n",
    "                                                    )\n",
    "\n",
    "    display(mistake_freq_df.head(n=10)) # Print 10 most frequent errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Check if both y_true and y_pred contain unknown tags, and ensure consistency\n",
    "print(f\"Unique tags in y_true: {set(y_true)}\")\n",
    "print(f\"Unique tags in y_pred: {set(y_pred)}\")\n",
    "\"\"\"\n",
    "\n",
    "test_acc, test_f1, test_recall, train_acc, train_f1, train_recall = calculate_results(Y_test, \n",
    "                                                                                        Y_train, \n",
    "                                                                                        predicts_test, \n",
    "                                                                                        predicts_train\n",
    "                                                                                        )\n",
    "\n",
    "print(\"Test Accuracy:\", round(test_acc, 3))\n",
    "print(\"Test F1 Score:\", round(test_f1, 3))\n",
    "print(\"Test recall:\", round(test_recall, 3))\n",
    "print(\"Train Accuracy:\", round(train_acc, 3))\n",
    "print(\"Train F1 Score:\", round(train_f1, 3))\n",
    "print(\"Train recall:\", round(train_recall, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def nltk_model(\\n        train_data, \\n        test_data\\n        ) : \\n    DFTagger = DefaultTagger(\"NN\")\\n    # Train the Unigram Tagger\\n    BigramTagger = BigramTagger(train_data, \\n                                backoff=DFTagger)\\n\\n    # Extract true labels and predicted labels from the test data\\n    Y_test, predicts_test = extract_tags(test_data)\\n    Y_train, predicts_train = extract_tags(train_data)\\n\\n    return Y_test, predicts_test, Y_train, predicts_train'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def data_to_nltk(df):\n",
    "    # Convert the data into the format that NLTK expects (list of tuples)\n",
    "    tagged_sentences = []\n",
    "    sentence = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        if row['WORD'] == \".\":  # End of a sentence (you may need to adjust this)\n",
    "            sentence.append((row['WORD'], row['POS']))\n",
    "            tagged_sentences.append(sentence)\n",
    "            sentence = []\n",
    "        else:\n",
    "            sentence.append((row['WORD'], row['POS']))\n",
    "\n",
    "    # Handle any remaining sentence\n",
    "    if sentence:\n",
    "        tagged_sentences.append(sentence)\n",
    "    return tagged_sentences\n",
    "\n",
    "def extract_words_and_tags(nested_list):\n",
    "    # Flatten the nested list of tuples\n",
    "    words = [word for sentence in nested_list for word, _ in sentence]\n",
    "    tags = [tag for sentence in nested_list for _, tag in sentence]\n",
    "    \n",
    "    # Convert the lists to numpy arrays\n",
    "    words_array = np.array(words, dtype=object)\n",
    "    tags_array = np.array(tags, dtype=object)\n",
    "    \n",
    "    return words_array, tags_array\n",
    "\n",
    "# Function to extract words and POS tags for classification report\n",
    "def extract_tags(tagged_data, tagger):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for sentence in tagged_data:\n",
    "        words, true_tags = zip(*sentence)  # separate words and tags\n",
    "        predicted_tags = []\n",
    "        \n",
    "        # Predict tags, handling unknown tags\n",
    "        for word in words:\n",
    "            \n",
    "            prediction = tagger.tag([word])[0][1] if tagger.tag([word]) else \"UNK\"\n",
    "            predicted_tags.append(prediction)\n",
    "        y_true.extend(true_tags)\n",
    "        y_pred.extend(predicted_tags)\n",
    "    \n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size dataset :  (20000, 10)\n"
     ]
    }
   ],
   "source": [
    "columns = [\"ID\", \"WORD\", \"LEMMA\", \"POS\", \"XPOS\", \"MORPH\", \"HEAD\", \"DEPREL\", \"DEPS\", \"MISC\"]\n",
    "\n",
    "# Read the file and convert it to a DataFrame\n",
    "df = pd.read_csv(path_en,\n",
    "                sep='\\t',\n",
    "                names=columns,\n",
    "                skip_blank_lines=True\n",
    "                )\n",
    "\n",
    "# run the hand-made function to clean data\n",
    "df = clean_data(df)\n",
    "\n",
    "tagged_sentences = data_to_nltk(df)\n",
    "\n",
    "X_lex, Y_lex = get_values(df)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train_data, test_data = train_test_split(tagged_sentences, \n",
    "                                         test_size=0.1, \n",
    "                                         random_state=42\n",
    "                                         )\n",
    "\n",
    "\n",
    "################## NLTK MODEL ##################\n",
    "# setup and train BigramTagger\n",
    "DFTagger = DefaultTagger(\"NN\")\n",
    "Tagger = BigramTagger(train_data, \n",
    "                    backoff=DFTagger)\n",
    "\n",
    "# Extract true labels and predicted labels from the test data\n",
    "Y_test_nltk, predicts_test_nltk = extract_tags(test_data, Tagger)\n",
    "Y_train_nltk, predicts_train_nltk = extract_tags(train_data, Tagger)\n",
    "################################################\n",
    "\n",
    "\n",
    "\n",
    "X_test, y_test = extract_words_and_tags(test_data)\n",
    "X_train, y_train = extract_words_and_tags(train_data)\n",
    "\n",
    "#get max word length\n",
    "max_word_len = max(max([len(w) for w in Y_lex]), max([len(w) for w in X_lex]))\n",
    "\n",
    "#Char2vec model\n",
    "vectorizer = TfidfVectorizer(lowercase=False, \n",
    "                            analyzer='char'\n",
    "                            )\n",
    "\n",
    "X = vectorizer.fit_transform(X_lex)\n",
    "dic = vectorizer.get_feature_names_out() # letter dictionary\n",
    "num_letters = len(dic)\n",
    "mx = X.T.dot(X) # letter cooccurence matrix\n",
    "mx = mx.toarray()\n",
    "\n",
    "#Vectorize X only\n",
    "X_lex_vec_train = [alpha_vec2(w, mx, max_word_len, dic) for w in X_train]\n",
    "X_lex_vec_test = [alpha_vec2(w, mx, max_word_len, dic) for w in X_test]\n",
    "\n",
    "# Encode Y\n",
    "list_tags = list_all_POS_tags(y = y_train)\n",
    "encoder_tag = LabelEncoder().fit(list_tags)\n",
    "\n",
    "Y_train = encoder_tag.transform(y_train)\n",
    "Y_test = encoder_tag.transform(y_test)\n",
    "\n",
    "# Build & train model\n",
    "best_model = ExtraTreesClassifier(n_estimators=10,\n",
    "                                n_jobs=-1,\n",
    "                                criterion='entropy',\n",
    "                                bootstrap=True\n",
    "                                )\n",
    "\n",
    "best_model.fit(X_lex_vec_train, Y_train)\n",
    "\n",
    "# predict both train and test sets\n",
    "predicts_test = best_model.predict(X_lex_vec_test)\n",
    "predicts_train = best_model.predict(X_lex_vec_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.842\n",
      "Test F1 Score: 0.837\n",
      "Test recall: 0.842\n",
      "Train Accuracy: 0.95\n",
      "Train F1 Score: 0.948\n",
      "Train recall: 0.95\n"
     ]
    }
   ],
   "source": [
    "test_acc, test_f1, test_recall, train_acc, train_f1, train_recall = calculate_results(Y_test, \n",
    "                                                                                        Y_train, \n",
    "                                                                                        predicts_test, \n",
    "                                                                                        predicts_train\n",
    "                                                                                        )\n",
    "\n",
    "print(\"Test Accuracy:\", round(test_acc, 3))\n",
    "print(\"Test F1 Score:\", round(test_f1, 3))\n",
    "print(\"Test recall:\", round(test_recall, 3))\n",
    "print(\"Train Accuracy:\", round(train_acc, 3))\n",
    "print(\"Train F1 Score:\", round(train_f1, 3))\n",
    "print(\"Train recall:\", round(train_recall, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.288\n",
      "Test F1 Score: 0.368\n",
      "Test recall: 0.288\n",
      "Train Accuracy: 0.308\n",
      "Train F1 Score: 0.391\n",
      "Train recall: 0.308\n"
     ]
    }
   ],
   "source": [
    "test_acc, test_f1, test_recall, train_acc, train_f1, train_recall = calculate_results(Y_test_nltk, \n",
    "                                                                                        Y_train_nltk, \n",
    "                                                                                        predicts_test_nltk, \n",
    "                                                                                        predicts_train_nltk\n",
    "                                                                                        )\n",
    "\n",
    "print(\"Test Accuracy:\", round(test_acc, 3))\n",
    "print(\"Test F1 Score:\", round(test_f1, 3))\n",
    "print(\"Test recall:\", round(test_recall, 3))\n",
    "print(\"Train Accuracy:\", round(train_acc, 3))\n",
    "print(\"Train F1 Score:\", round(train_f1, 3))\n",
    "print(\"Train recall:\", round(train_recall, 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
